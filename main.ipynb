{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penggunaan untuk digunakan di Terminal\n",
    "    # output langsung \n",
    "        # main.py --input pedestrians.mp4\n",
    "    #output Langsung dan save File\n",
    "        # main.py --input pedestrians.mp4 --output output.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mods import pengaturan as config\n",
    "from mods.deteksi_pdv import detect_people\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dipakai Kalau mau bikin Argument untuk penggunaan Di terminal\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-i\", \"--input\", type=str, default=\"\",\n",
    "#\thelp=\"path to (optional) input video file\")\n",
    "#ap.add_argument(\"-o\", \"--output\", type=str, default=\"\",\n",
    "#\thelp=\"path to (optional) output video file\")\n",
    "#ap.add_argument(\"-d\", \"--display\", type=int, default=1,\n",
    "#\thelp=\"whether or not output frame should be displayed\")\n",
    "#args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the COCO class labels our YOLO model was trained on\n",
    "labelsPath = os.path.sep.join([config.MODEL_PATH, \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# derive the paths to the YOLO weights and model configuration\n",
    "weightsPath = os.path.sep.join([config.MODEL_PATH, \"yolov3.weights\"])\n",
    "configPath = os.path.sep.join([config.MODEL_PATH, \"yolov3.cfg\"])\n",
    "\n",
    "input_file = \"input/gelora_0710.mp4\"\n",
    "input_display = 1\n",
    "output_file = \"output/gelora_0720.avi\"\n",
    "jam = \"07:10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading YOLO from disk...\n",
      "[INFO] setting preferable backend and target to CUDA...\n",
      "[INFO] accessing video stream...\n"
     ]
    }
   ],
   "source": [
    "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "\n",
    "# check if we are going to use GPU\n",
    "if config.USE_GPU:\n",
    "    # set CUDA as the preferable backend and target\n",
    "    print(\"[INFO] setting preferable backend and target to CUDA...\")\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# determine only the *output* layer names that we need from YOLO\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# initialize the video stream and pointer to output video file\n",
    "print(\"[INFO] accessing video stream...\")\n",
    "vs = cv2.VideoCapture(input_file if input_file else 0)\n",
    "writer = None\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    # if the frame was not grabbed, then we have reached the end\n",
    "    # of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # resize the frame and then detect people (and only people) in it\n",
    "    frame = imutils.resize(frame, width=700)\n",
    "    results = detect_people(frame, net, ln,\n",
    "        personIdx=LABELS.index(\"person\"))\n",
    "\n",
    "    # initialize the set of indexes that violate the minimum social\n",
    "    # distance\n",
    "    violate = set()\n",
    "\n",
    "    # ensure there are *at least* two people detections (required in\n",
    "    # order to compute our pairwise distance maps)\n",
    "    if len(results) >= 2:\n",
    "        # extract all centroids from the results and compute the\n",
    "        # Euclidean distances between all pairs of the centroids\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        # loop over the upper triangular of the distance matrix\n",
    "        for i in range(0, D.shape[0]):\n",
    "            for j in range(i + 1, D.shape[1]):\n",
    "                # check to see if the distance between any two\n",
    "                # centroid pairs is less than the configured number\n",
    "                # of pixels\n",
    "                if D[i, j] < config.MIN_DISTANCE:\n",
    "                    # update our violation set with the indexes of\n",
    "                    # the centroid pairs\n",
    "                    violate.add(i)\n",
    "                    violate.add(j)\n",
    "\n",
    "    # loop over the results\n",
    "    for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "        # extract the bounding box and centroid coordinates, then\n",
    "        # initialize the color of the annotation\n",
    "        (startX, startY, endX, endY) = bbox\n",
    "        (cX, cY) = centroid\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # if the index pair exists within the violation set, then\n",
    "        # update the color\n",
    "        if i in violate:\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # draw (1) a bounding box around the person and (2) the\n",
    "        # centroid coordinates of the person,\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "        cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "    # draw the total number of social distancing violations on the\n",
    "    # output frame\n",
    "    text = \"Physical Distancing Violations: {}\".format(len(violate))\n",
    "    cv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "\n",
    "    # check to see if the output frame should be displayed to our\n",
    "    # screen\n",
    "    if input_display > 0:\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # if an output video file path has been supplied and the video\n",
    "    # writer has not been initialized, do so now\n",
    "    if output_file != \"\" and writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(output_file, fourcc, 25,\n",
    "            (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    # if the video writer is not None, write the frame to the output\n",
    "    # video file\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "        \n",
    "    #new dataframe with same columns\n",
    "    df = pd.DataFrame({'Physical Distancing Violation': [len(violate)],\n",
    "                       'Jam': [jam]})\n",
    "    writerEx = pd.ExcelWriter('data output.xlsx', engine='openpyxl')\n",
    "    #try to open an existing workbook\n",
    "    writerEx.book = load_workbook('data output.xlsx')\n",
    "    # copy existing sheets\n",
    "    writerEx.sheets = dict((ws.title, ws) for ws in writerEx.book.worksheets)\n",
    "    # read existing file\n",
    "    reader = pd.read_excel(r'data output.xlsx')\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writerEx,sheet_name='PSBB Violation Raw',index=False,header=False,startrow=len(reader)+1)\n",
    "    writerEx.close()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalau Belumm Bikin Excel nya Run Dulu yang ini, kalau udh tidak usah\n",
    "# Framedata kolom data-data yang dibikin di excel\n",
    "df = pd.DataFrame({'Physical Distancing Violation': ['Null'],\n",
    "                   'Jam': ['Null']})\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('data output.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='PSBB Violation Raw', index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
